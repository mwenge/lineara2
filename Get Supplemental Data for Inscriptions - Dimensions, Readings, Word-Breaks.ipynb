{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "json_file = open('imagemaps.js')\n",
    "imagemaps = json.load(json_file)\n",
    "\n",
    "json_file = open('150-inscriptions.js')\n",
    "inscriptions = json.load(json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _ctypes import PyObj_FromPtr\n",
    "import json\n",
    "import re\n",
    "\n",
    "class NoIndent(object):\n",
    "    \"\"\" Value wrapper. \"\"\"\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "\n",
    "\n",
    "class MyEncoder(json.JSONEncoder):\n",
    "    FORMAT_SPEC = '@@{}@@'\n",
    "    regex = re.compile(FORMAT_SPEC.format(r'(\\d+)'))\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # Save copy of any keyword argument values needed for use here.\n",
    "        self.__sort_keys = kwargs.get('sort_keys', None)\n",
    "        super(MyEncoder, self).__init__(**kwargs)\n",
    "\n",
    "    def default(self, obj):\n",
    "        return (self.FORMAT_SPEC.format(id(obj)) if isinstance(obj, NoIndent)\n",
    "                else super(MyEncoder, self).default(obj))\n",
    "\n",
    "    def encode(self, obj):\n",
    "        format_spec = self.FORMAT_SPEC  # Local var to expedite access.\n",
    "        json_repr = super(MyEncoder, self).encode(obj)  # Default JSON.\n",
    "\n",
    "        # Replace any marked-up object ids in the JSON repr with the\n",
    "        # value returned from the json.dumps() of the corresponding\n",
    "        # wrapped Python object.\n",
    "        for match in self.regex.finditer(json_repr):\n",
    "            # see https://stackoverflow.com/a/15012814/355230\n",
    "            id = int(match.group(1))\n",
    "            no_indent = PyObj_FromPtr(id)\n",
    "            json_obj_repr = json.dumps(no_indent.value, sort_keys=self.__sort_keys, ensure_ascii=False)\n",
    "\n",
    "            # Replace the matched id string with json formatted representation\n",
    "            # of the corresponding Python object.\n",
    "            json_repr = json_repr.replace(\n",
    "                            '\"{}\"'.format(format_spec.format(id)), json_obj_repr)\n",
    "\n",
    "        return json_repr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the x-coordinate position of each glyph on each tablet.\n",
    "# We'll use this to figure out possible line-breaks in the tablet.\n",
    "glyph_x_positions = {i[\"img\"].split('-')[0][7:]: [a[\"coords\"][\"x\"] for a in i[\"areas\"]]\n",
    "                     for i in imagemaps\n",
    "                     if \"Inscription\" in i[\"img\"]\n",
    "                    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The glyphs in each inscription as a list.\n",
    "inscription_glyphs = { i[\"name\"]: list(i[\"parsedInscription\"].replace('\\n','').replace('\\U0001076b',\"\")) \n",
    "                                        for i in inscriptions[\"inscriptions\"]}\n",
    "# The position in each list of the 'separator' glyph\n",
    "sep_indices = {k: [i for i, v in enumerate(ig) if v == \"êÑÅ\"] for k,ig in inscription_glyphs.items() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a mock position for the separator glyph (\"êÑÅ\") that I didn't bother capturing when collecting\n",
    "# the position of each glyph in each image.\n",
    "for k,v in sep_indices.items():\n",
    "    if not v:\n",
    "        continue\n",
    "    if not k in glyph_x_positions:\n",
    "        continue\n",
    "    gxp = glyph_x_positions[k]\n",
    "    if not gxp:\n",
    "        continue\n",
    "    for i in v: \n",
    "        if (i > len(gxp)):\n",
    "            print(\"Skipping \" + str(i) + \" in \" + k)\n",
    "            continue\n",
    "        p = gxp[i-1] if i > 0 else 0\n",
    "        gxp.insert(i, p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the index into each inscription of the probable line-break positions\n",
    "newline_indices = { k: [i for i, v in enumerate(t) if not i or (v+5) < t[i-1]] \n",
    "                   for k,t in glyph_x_positions.items() }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 7, 14, 23, 32, 38, 46, 52, 60],\n",
       " [('êò∏', (0, 24)),\n",
       "  ('êò≥', (1, 75)),\n",
       "  ('êòö', (2, 128)),\n",
       "  ('êÑÅ', (3, 128)),\n",
       "  ('êôã', (4, 181)),\n",
       "  ('êÑí', (5, 242)),\n",
       "  ('êÑá', (6, 255)),\n",
       "  ('êôú', (7, 18)),\n",
       "  ('êÑé', (8, 52)),\n",
       "  ('êùÉ', (9, 114)),\n",
       "  ('êò∏', (10, 146)),\n",
       "  ('êòÅ', (11, 194)),\n",
       "  ('êÑá', (12, 227)),\n",
       "  ('êùé', (13, 242)),\n",
       "  ('êò´', (14, 10)),\n",
       "  ('êôç', (15, 71)),\n",
       "  ('êôã', (16, 112)),\n",
       "  ('êÑí', (17, 162)),\n",
       "  ('êÑá', (18, 200)),\n",
       "  ('êùÜ', (19, 198)),\n",
       "  ('êôú', (20, 227)),\n",
       "  ('êÑé', (21, 265)),\n",
       "  ('êùï', (22, 273)),\n",
       "  ('êò∏', (23, 11)),\n",
       "  ('êòÅ', (24, 36)),\n",
       "  ('êùé', (25, 69)),\n",
       "  ('êòû', (26, 94)),\n",
       "  ('êòò', (27, 131)),\n",
       "  ('êôã', (28, 170)),\n",
       "  ('êÑê', (29, 220)),\n",
       "  ('êÑå', (30, 251)),\n",
       "  ('êôú', (31, 275)),\n",
       "  ('êÑä', (32, 14)),\n",
       "  ('êùÄ', (33, 47)),\n",
       "  ('êò∏', (34, 89)),\n",
       "  ('êòÅ', (35, 132)),\n",
       "  ('êùï', (36, 172)),\n",
       "  ('êòÄ', (37, 201)),\n",
       "  ('êòπ', (38, 14)),\n",
       "  ('êôã', (39, 66)),\n",
       "  ('êÑê', (40, 118)),\n",
       "  ('êÑã', (41, 164)),\n",
       "  ('êôú', (42, 181)),\n",
       "  ('êÑä', (43, 219)),\n",
       "  ('êùÉ', (44, 250)),\n",
       "  ('êò∏', (45, 284)),\n",
       "  ('êòÅ', (46, 30)),\n",
       "  ('êùï', (47, 75)),\n",
       "  ('êôÇ', (48, 125)),\n",
       "  ('êòÅ', (49, 164)),\n",
       "  ('êôã', (50, 205)),\n",
       "  ('êÑò', (51, 241)),\n",
       "  ('êÑâ', (52, 35)),\n",
       "  ('êùÜ', (53, 99)),\n",
       "  ('êôú', (54, 129)),\n",
       "  ('êÑÅ', (55, 129)),\n",
       "  ('êôÇ', (56, 181)),\n",
       "  ('êòÅ', (57, 213)),\n",
       "  ('êÑë', (58, 256)),\n",
       "  ('êÑã', (59, 297)),\n",
       "  ('êùÖ', (60, 33)),\n",
       "  ('êò∏', (61, 79)),\n",
       "  ('êòÅ', (62, 124)),\n",
       "  ('êÑå', (63, 175))])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(newline_indices[\"HT123+124a\"], \n",
    " list(zip(inscription_glyphs[\"HT123+124a\"], list(enumerate(glyph_x_positions[\"HT123+124a\"])))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 108\n",
      "Before filtering out erasures(êù´) 267\n",
      "After filtering out erasures(êù´) 267\n"
     ]
    }
   ],
   "source": [
    "# Get the inscriptions with uncertain readings\n",
    "inscription_glyphs = { i[\"name\"]: list(i[\"parsedInscription\"].replace('\\n','')) \n",
    "                                        for i in inscriptions[\"inscriptions\"]}\n",
    "\n",
    "rf = open('000-UncertainReadings.txt')\n",
    "rf_lines = [l.strip() for l in rf.readlines() if any([s in l for s in [\"doubtful\", \"erased\"]])]\n",
    "uncertains = {l[0]: [s for s in l[1].split(',') if s != 'eol'] \n",
    "              for l in [ l.split('\\t') for l in rf_lines ] }\n",
    "\n",
    "# Count how many match the actual number of glyphs in the inscription. These are the only\n",
    "# ones we can actually use\n",
    "r=[]\n",
    "for k,v in uncertains.items():\n",
    "    if k not in inscription_glyphs:\n",
    "        continue\n",
    "    r += [len(v) == len(inscription_glyphs[k])]\n",
    "print(r.count(True), r.count(False))\n",
    "\n",
    "# Limit to ones where the number of glyphs in `uncertains` matches the number of glyphs in the\n",
    "# inscription\n",
    "uncertains = {k:v for k,v in uncertains.items()\n",
    "              if k in inscription_glyphs and len(v) == len(inscription_glyphs[k])}\n",
    "print(\"Before filtering out erasures(êù´)\", len(uncertains))\n",
    "\n",
    "# Now we need to remove the items in the `uncertains` lists that refer to 'êù´' (i.e. '\\U0001076b')\n",
    "# in the inscription, as the inscription we will tabulate will not contain 'êù´' glyphs.\n",
    "for k,v in uncertains.items():\n",
    "    if k not in inscription_glyphs:\n",
    "        continue\n",
    "    glyphs = inscription_glyphs[k]\n",
    "    erasures = [i for i, g in enumerate(glyphs) if g == '\\U0001076b']\n",
    "    us = [u for i,u in enumerate(uncertains[k]) if i not in erasures]\n",
    "    uncertains[k] = us\n",
    "\n",
    "inscription_glyphs = { i[\"name\"]: list(i[\"parsedInscription\"].replace('\\n','').replace('\\U0001076b',\"\")) \n",
    "                                        for i in inscriptions[\"inscriptions\"]}\n",
    "uncertains = {k:v for k,v in uncertains.items()\n",
    "              if k in inscription_glyphs and len(v) == len(inscription_glyphs[k])}\n",
    "print(\"After filtering out erasures(êù´)\",len(uncertains))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = open('dimensions-gorila-ocr-cleanedup.txt')\n",
    "in_lines = inf.readlines()\n",
    "raw_dimensions = { i.replace(' ',''): v.strip() for i,_,v in [l.split('\\t') for l in in_lines] }\n",
    "catalogue = { i.replace(' ',''): v.strip() for i,v,_ in [l.split('\\t') for l in in_lines] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = {k: {\n",
    "                    \"length\": l.strip().replace(',','.')\n",
    "                  , \"height\": h.strip().replace(',','.')\n",
    "                  , \"thickness\": t.replace(',','.').replace('cm','').strip()\n",
    "                  , \"unit\" : \"cm\"\n",
    "                  , \"source\": \"GORILA OCR\"\n",
    "                 } \n",
    "              for k,(l,h,t) in [[k, v.split('x')] for k,v in raw_dimensions.items()\n",
    "                             if len(v.split('x')) == 3]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabulation = list(inscriptions[\"inscriptions\"][0][\"parsedInscription\"].replace('\\n','').replace(\"êù´\",\"\"))\n",
    "\n",
    "# Get the word each glyph is in.\n",
    "words = [ w for w in \n",
    "         [list(w.replace('\\n','').replace(\"êù´\",\"\")) \n",
    "          for w in inscriptions[\"inscriptions\"][0][\"words\"]]\n",
    "         if w]\n",
    "word_for_glyph = [i for i,w in enumerate(words) for c in w]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create the final output files\n",
    "\"\"\"\n",
    "import re\n",
    "import copy\n",
    "\n",
    "json_file = open('150-inscriptions.js')\n",
    "inscriptions = json.load(json_file)\n",
    "\n",
    "of = \"inscriptions\" + os.sep\n",
    "supplements = []\n",
    "for inscription in inscriptions[\"inscriptions\"]:\n",
    "    name = inscription[\"name\"]\n",
    "    supplement = {}\n",
    "    lookup_name = re.sub(r'[abcd]', '', name)\n",
    "    # Get the inscription as a list of glyphs\n",
    "    tabulation = list(inscription[\"parsedInscription\"].replace('\\n','').replace(\"êù´\",\"\"))\n",
    "\n",
    "    # Get the word each glyph is in.\n",
    "    words = [ w for w in \n",
    "             [list(w.replace('\\n','').replace(\"êù´\",\"\")) \n",
    "              for w in inscription[\"words\"]]\n",
    "             if w]\n",
    "    word_for_glyph = [i for i,w in enumerate(words) for c in w]\n",
    "    \n",
    "    # If the inscription has multiple lines, split each line out into its own element in the list\n",
    "    if name in newline_indices and len(newline_indices[name]) > 1:\n",
    "        # Figure out the to/from index for each line\n",
    "        ni = newline_indices[name]\n",
    "        # The to/from is a list of tuples with the to/from indices\n",
    "        segments = list(zip(ni[:-1], ni[1:]))\n",
    "        # Split the glyph list into its lines\n",
    "        tabulation = [list(zip(tabulation[b:e],\n",
    "                               uncertains[lookup_name][b:e] if lookup_name in uncertains else [''] * (e-b),\n",
    "                               word_for_glyph[b:e])\n",
    "                          )\n",
    "                      for b,e in segments + [(segments[-1][1],len(tabulation))]]\n",
    "    else:\n",
    "        l = len(tabulation)\n",
    "        tabulation = [zip(tabulation,\n",
    "                        uncertains[lookup_name][0:l] if lookup_name in uncertains else [''] * (l),\n",
    "                        word_for_glyph[0:l])]\n",
    "    tabulation = [NoIndent([c for c in t]) for t in tabulation]\n",
    "    supplement[\"tabulation\"] = tabulation\n",
    "\n",
    "    words = [w for w in [ w.replace('\\n','').replace(\"êù´\",\"\")\n",
    "               for w in inscription[\"words\"]] if w]\n",
    "    supplement[\"tabulatedWords\"] = NoIndent(words)\n",
    "\n",
    "    supplement[\"catalogue\"] = catalogue[lookup_name] if lookup_name in catalogue else \"\"\n",
    "    supplement[\"dimensionsRaw\"] = raw_dimensions[lookup_name] if lookup_name in raw_dimensions else \"\"\n",
    "    supplement[\"dimensions\"] = dimensions[lookup_name] if lookup_name in dimensions else \"\"\n",
    "    supplement[\"name\"] = name\n",
    "    supplements.append(supplement)\n",
    "    \n",
    "    output_file = open(of + inscription[\"name\"] + \".json\", \"w\")\n",
    "    output_file.write(json.dumps(supplement, cls=MyEncoder, sort_keys=True, indent=2, ensure_ascii=False))\n",
    "    output_file.close()\n",
    "\n",
    "output_file = open(\"supplement.json\", \"w\")\n",
    "output_file.write(json.dumps(supplements, cls=MyEncoder, sort_keys=True, indent=2, ensure_ascii=False))\n",
    "output_file.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
